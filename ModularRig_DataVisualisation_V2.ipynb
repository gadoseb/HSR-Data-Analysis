{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nAP3NSvesp15"},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","import datetime\n","import re\n","import glob\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as mpatches\n","import shutil\n","\n","from datetime import datetime\n","import pytz\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","pd.set_option('display.max_columns', None)\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format='retina'\n","\n","localtime = pytz.timezone('Europe/London')"]},{"cell_type":"markdown","metadata":{"id":"qE9cxm2hsp19"},"source":["# Open and Load the Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"liCIDl1Csp1_"},"outputs":[],"source":["def process_modular_files(foldersearchpath):\n","    \"\"\"\n","    Process the modular rig files.\n","\n","    Parameters:\n","    foldersearchpath (str): The path of the folder containing the modular rig files.\n","\n","    Returns:\n","    - df_modular: The processed data from the modular rig files.\n","    - state_numbers: List of unique state numbers encountered in the files.\n","    \"\"\"\n","    # Step 0: Initialise an empty list to store individual dataframes\n","    dfs = []\n","\n","    # Step 0: Initialise an empty list to store unique state numbers\n","    state_numbers = []\n","\n","    # Step 1: Define an empty dataframe to store the modular rig data\n","    df_modular = pd.DataFrame()\n","\n","    # Step 2: Identify files with \"-10s\" in the filename\n","    modular_files = []\n","    for filename in glob.glob(foldersearchpath + '*-10s.csv'):\n","        modular_files.append(filename)\n","\n","    # Step 3: Iterate through modular files\n","    for filename in modular_files:\n","        # Step 4: Read the file and select required columns\n","        df = pd.read_csv(filename, usecols=['runner_timestamp', '4-20mA Sensor 1',\n","                                            'MFC flow rate', 'Solenoid States', 'volume'])\n","\n","        # Step 5: Extract state number from filename\n","        state_number = filename.split(\"-\")[0].split(\"\\\\\")[-1]\n","\n","        # Step 6: Check if the state number is already encountered\n","        if state_number not in state_numbers:\n","            # Step 7: Add the state number to the list of unique state numbers\n","            state_numbers.append(state_number)\n","\n","        # Step 8: Assign state and color based on state number\n","        df[\"state_number\"] = state_number\n","        # Step 8: Assign state and color based on state number\n","        if state_number.startswith('D'):\n","            df[\"state\"] = \"D\"\n","            df[\"colour\"] = \"Desorption\"\n","        else:\n","            df[\"state\"] = \"A\"\n","            df[\"colour\"] = \"Absorption\"\n","\n","        # Step 9: Rename columns\n","        df.rename(columns={\"runner_timestamp\": \"Timestamp\", \"4-20mA Sensor 1\": \"Pressure (bar)\",\n","                           \"MFC flow rate\": \"Flow (L/min)\", \"Solenoid States\": \"Solenoid States\",\n","                           \"volume\": \"Volume (L)\"}, inplace=True)\n","\n","        # Step 10: Set index to runner timestamp and sort chronologically\n","        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n","        df.set_index('Timestamp', inplace=True)\n","        df.sort_index(inplace=True)\n","\n","        # Step 11: Add a column for the filename\n","        df['filename'] = os.path.basename(filename)\n","\n","        # Step 12: Append dataframe to the list of individual dataframes\n","        dfs.append(df)\n","\n","    # Step 13: Concatenate all dataframes in the list\n","    df_modular = pd.concat(dfs)\n","\n","    # Step 14: Replace the signal of unplugged sensors, i.e. 0xFF, with NaN values\n","    df_modular.replace(\"0xFF\", np.NaN, inplace=True)\n","    df_modular.replace(\"0xFF \", np.NaN, inplace=True)\n","\n","    return df_modular, state_numbers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k2CFK62Gsp1_"},"outputs":[],"source":["def process_strain_files(foldersearchpath, state_numbers):\n","    \"\"\"\n","    Process the strain files in the specified folder.\n","\n","    Parameters:\n","    - foldersearchpath (str): Path to the folder containing the strain files.\n","    - state_numbers (list): List of unique state numbers encountered in the modular files.\n","\n","    Returns:\n","    - df_strain (DataFrame): DataFrame containing processed strain data with state number as an additional column.\n","    \"\"\"\n","    # Step 0: Initialise an empty list to store individual dataframes\n","    dfs = []\n","\n","    # Step 1: Iterate over each state number\n","    for state_number in state_numbers:\n","        # Step 2: Identify strain files with the specified state number\n","        strain_files = glob.glob(foldersearchpath + f'*-{state_number}.csv')\n","\n","        for filename in strain_files:\n","            # Step 3: Check if filename contains 4 dashes\n","            if filename.count('-') != 4:\n","                continue\n","\n","            # Step 4: Read the file and skip the first 4 rows\n","            df = pd.read_csv(filename, skiprows=4, sep=\",\", usecols=['Timestamp',\n","                            'M1AI1', 'M2AI0', 'M2AI1', 'M2AI2', 'M2AI3', 'M2AI4', 'M2AI7', 'M3AI0',\n","                            'M3AI1', 'M3AI2', 'M3AI3', 'M3AI4'], parse_dates=['Timestamp']).set_index('Timestamp')\n","            df.index = df.index.values.astype(dtype='datetime64')\n","\n","            # Step 5: Rename columns\n","            df.rename(columns={\"M1AI1\": \"strain1\", \"M2AI0\": \"strain2\", \"M2AI1\": \"strain3\",\n","                               \"M2AI2\": \"strain4\", \"M2AI3\": \"strain5\", \"M2AI4\": \"strain6\",\n","                               \"M2AI7\": \"strain7\", \"M3AI0\": \"strain8\", \"M3AI1\": \"strain9\",\n","                               \"M3AI2\": \"strain10\", \"M3AI3\": \"strain11\", \"M3AI4\": \"strain12\"}, inplace=True)\n","\n","            # Step 6: Set the name of the index to 'Timestamp'\n","            df.index.name = 'Timestamp'\n","\n","            # Step 7: Convert timestamps in df_strain index to match the format of df_modular\n","            df.index = pd.to_datetime(df.index).strftime('%Y-%m-%d %H:%M:%S')\n","\n","            #df['state_number'] = state_number\n","\n","            # Step 8: Append dataframe to the list\n","            dfs.append(df)\n","\n","    # Step 9: Concatenate all dataframes in the list\n","    df_strain = pd.concat(dfs)\n","\n","    # Step 10: Convert Timestamp column in df_strain to datetime64[ns]\n","    df_strain.index = pd.to_datetime(df_strain.index)\n","\n","    return df_strain"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HU08rssRsp2A"},"outputs":[],"source":["def process_temperature_files(foldersearchpath, state_numbers):\n","    \"\"\"\n","    Process the temperature files in the specified folder.\n","\n","    Parameters:\n","    - foldersearchpath (str): Path to the folder containing the temperature files.\n","    - state_numbers (list): List of unique state numbers.\n","\n","    Returns:\n","    - df_temperature (DataFrame): DataFrame containing the processed temperature data.\n","    \"\"\"\n","    # Step 0: Initialise an empty list to store individual dataframes\n","    dfs = []\n","\n","    # Step 1: Iterate through state numbers\n","    for state_number in state_numbers:\n","        # Step 2: Find all temperature files for the current state number\n","        temperature_files = glob.glob(foldersearchpath + f'*-{state_number}.csv') + glob.glob(foldersearchpath + f'*-{state_number}_*.csv')\n","\n","        # Step 3: Iterate through temperature files\n","        for filename in temperature_files:\n","            # Step 4: Check if filename contains 1 dash\n","            if filename.count('-') != 1:\n","                continue\n","\n","            # Step 5: Read the file\n","            df = pd.read_csv(filename)\n","\n","            # Step 6: Rename the first column to 'Timestamp'\n","            df.rename(columns={df.columns[0]: 'Timestamp'}, inplace=True)\n","\n","            # Step 7: Set the 'Timestamp' column as datetime and format it\n","            df['Timestamp'] = pd.to_datetime(df['Timestamp']).dt.strftime('%Y-%m-%d %H:%M:%S')\n","\n","            # Step 8: Set the 'Timestamp' column as the index\n","            df.set_index('Timestamp', inplace=True)\n","\n","            # Step 9: Append dataframe to the list\n","            dfs.append(df)\n","\n","    # Step 10: Concatenate all dataframes in the list\n","    df_temperature = pd.concat(dfs)\n","\n","    # Step 11: Convert Timestamp column in df_temperature to datetime64[ns]\n","    df_temperature.index = pd.to_datetime(df_temperature.index)\n","\n","    return df_temperature"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YnwRtsFjsp2A"},"outputs":[],"source":["# Define folderpath and reactor_id\n","folderpath = \"C:\\\\Users\\\\Sebastiano Gadolini\\\\Documents\\\\Python Scripts\\\\MogRig_DataAnalysis\\\\\"\n","\n","#reactor_id = \"CPE78683\"\n","foldersearchpath = folderpath #+ reactor_id + \"\\\\\"\n","\n","# Call the function to process modular files\n","df_modular, state_numbers = process_modular_files(foldersearchpath)\n","# Call the function to process strain files\n","df_strain = process_strain_files(foldersearchpath, state_numbers)\n","# Call the function to process temperature files\n","df_temperature = process_temperature_files(foldersearchpath, state_numbers)\n","\n","# Drop columns strain10, strain11, and strain12 if not connected\n","df_strain.drop(columns=['strain10', 'strain11', 'strain12'], inplace=True)"]},{"cell_type":"markdown","metadata":{"id":"2wYtDQx4sp2B"},"source":["# Dataset Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OwOyzS1Asp2B"},"outputs":[],"source":["def merge_dataframes(df_modular, df_strain, df_temperature):\n","    \"\"\"\n","    Merge the dataframes based on the timestamps in df_modular.\n","\n","    Parameters:\n","    - df_modular (DataFrame): DataFrame containing modular rig data.\n","    - df_strain (DataFrame): DataFrame containing strain data.\n","    - df_temperature (DataFrame): DataFrame containing temperature data.\n","\n","    Returns:\n","    - df_full (DataFrame): Merged DataFrame.\n","    \"\"\"\n","    # Step 0: Sort the indices of df_modular and df_strain\n","    df_modular.sort_index(inplace=True)\n","    df_strain.sort_index(inplace=True)\n","    df_temperature.sort_index(inplace=True)\n","\n","    # Step 1: Merge df_modular with df_strain on Timestamp\n","    df_full = pd.merge_asof(df_modular, df_strain, left_index=True, right_index=True, tolerance=pd.Timedelta(\"1 minute\"), direction='nearest')\n","\n","    # Step 2: Merge the result with df_temperature on Timestamp\n","    df_full = pd.merge_asof(df_full, df_temperature, left_index=True, right_index=True, tolerance=pd.Timedelta(\"1 minute\"), direction='nearest')\n","\n","    # Step 3: Replace the signal of unplugged sensors with NaN values\n","    df_full.replace(\"0xFF\", np.NaN, inplace=True)\n","    df_full.replace(\"0xFF \", np.NaN, inplace=True)\n","\n","    # Step 4: Check if we are in BST/DST, if True, then add an hour to the temp data\n","    if len(df_temperature) > 0:\n","        if bool(localtime.localize(df_modular.index[0]).dst()):\n","            df_temperature.index = df_temperature.index + pd.DateOffset(hours=1)\n","        df_temperature.sort_index(inplace=True)\n","    df_full.sort_index(inplace=True)\n","\n","    return df_full"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XuzNb6P9sp2C"},"outputs":[],"source":["# Call the function to merge the dataframes\n","df_full = merge_dataframes(df_modular, df_strain, df_temperature)"]},{"cell_type":"markdown","metadata":{"id":"1Xj41d4bsp2C"},"source":["# Data Visualisation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MsZ3VmRosp2C"},"outputs":[],"source":["def flow_rate_chart(df, state_number, plot_filepath=None):\n","    \"\"\"\n","    Generate a scatter plot of flow rate over time.\n","\n","    Parameters:\n","    - df (DataFrame): DataFrame containing flow rate data.\n","    - state_number (str): State number for the plot.\n","    - folderpath (str, optional): Path to the folder to save the plot. If None, the plot will not be saved.\n","\n","    Returns:\n","    None\n","    \"\"\"\n","    fig, ax = plt.subplots(figsize=(6, 6))\n","\n","    # Define colors for different states\n","    colors = {'Absorption': 'tab:blue', 'Desorption': 'tab:orange'}\n","\n","    # Scatter plot of flow rate over time with color based on state\n","    ax.scatter(df['Time since start (h)'], df['Flow (L/min)'], c=df['colour'].map(colors), marker=\".\")\n","\n","    ax.legend()\n","\n","    ax.set_xlabel(\"Time Elapsed (h)\")\n","    ax.set_ylabel(\"Flow (L/min)\")\n","\n","    # Save the plot if plot_filepath is provided\n","    if plot_filepath:\n","        plt.savefig(plot_filepath, format='png', bbox_inches='tight')\n","        plt.close()  # Close the plot to prevent it from being displayed\n","    else:\n","        plt.close()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bewyug0Bsp2C"},"outputs":[],"source":["def flow_rate_temp_chart(df, name, temp_columns, plot_filepath=None):\n","    \"\"\"\n","    Generate a scatter plot of flow rate and temperature over time.\n","\n","    Parameters:\n","    - df (DataFrame): DataFrame containing flow rate and temperature data.\n","    - name (str): Name for the plot.\n","    - temp_columns (list): List of column names containing temperature data.\n","\n","    Returns:\n","    None\n","    \"\"\"\n","    fig, ax = plt.subplots(figsize=(10, 6))\n","    ax2 = ax.twinx()\n","\n","    # Scatter plot of flow rate over time\n","    ax2.scatter(df['Time since start (h)'], df['Flow (L/min)'], color=\"aqua\", marker=\".\", label=df.iloc[0].state_number + \" flow rate\")\n","\n","    # Scatter plot of temperature over time\n","    for temp in temp_columns:\n","        ax.scatter(df['Time since start (h)'], df[temp], marker=\".\", label=temp)\n","\n","    ax.legend(bbox_to_anchor=(1.1, 1.0), loc='upper left')\n","    ax2.legend(bbox_to_anchor=(1.1, 0.5), loc='upper left')\n","\n","    ax.set_xlabel(\"Time Elapsed (h)\")\n","    ax2.set_ylabel(\"Flow (L/min)\")\n","    ax.set_ylabel(\"Temperature (C)\")\n","\n","    plt.tight_layout()\n","\n","    # Save the plot if plot_filepath is provided\n","    if plot_filepath:\n","        plt.savefig(plot_filepath, format='png', bbox_inches='tight')\n","        plt.close()  # Close the plot to prevent it from being displayed\n","    else:\n","        plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BSpOf18Lsp2D"},"outputs":[],"source":["def volume_chart(df, name, plot_filepath=None):\n","    \"\"\"\n","    Generate a scatter plot of volume over time.\n","\n","    Parameters:\n","    - df (DataFrame): DataFrame containing volume data.\n","    - name (str): Name for the plot.\n","\n","    Returns:\n","    None\n","    \"\"\"\n","    fig, ax = plt.subplots(figsize=(6, 6))\n","\n","    # Define colors for different states\n","    colors = {'Absorption': 'tab:blue', 'Desorption': 'tab:orange'}\n","\n","    # Scatter plot of volume over time with color based on state\n","    ax.scatter(df['Time since start (h)'], df['Volume cumulative sum'], c=df['colour'].map(colors), marker=\".\", label=df.iloc[0].state_number)\n","\n","    ax.legend()\n","\n","    ax.set_xlabel(\"Time Elapsed (h)\")\n","    ax.set_ylabel(\"Volume (L)\")\n","\n","    # Save the plot if plot_filepath is provided\n","    if plot_filepath:\n","        plt.savefig(plot_filepath, format='png', bbox_inches='tight')\n","        plt.close()  # Close the plot to prevent it from being displayed\n","    else:\n","        plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DrMowr5csp2D"},"outputs":[],"source":["def pressure_chart(df, name, plot_filepath=None):\n","    \"\"\"\n","    Generate a scatter plot of pressure over time.\n","\n","    Parameters:\n","    - df (DataFrame): DataFrame containing pressure data.\n","    - name (str): Name for the plot.\n","\n","    Returns:\n","    None\n","    \"\"\"\n","    fig, ax = plt.subplots(figsize=(6, 6))\n","\n","    # Define colors for different states\n","    colors = {'Absorption': 'tab:blue', 'Desorption': 'tab:orange'}\n","\n","    # Scatter plot of pressure over time with color based on state\n","    ax.scatter(df[\"Time since start (h)\"], df['Pressure (bar)'], c=df['colour'].map(colors), marker=\".\", label=df.iloc[0].state_number)\n","\n","    ax.legend()\n","\n","    ax.set_xlabel(\"Time Elapsed (h)\")\n","    ax.set_ylabel(\"Pressure (bar)\")\n","\n","    # Save the plot if plot_filepath is provided\n","    if plot_filepath:\n","        plt.savefig(plot_filepath, format='png', bbox_inches='tight')\n","        plt.close()  # Close the plot to prevent it from being displayed\n","    else:\n","        plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5_2bYobsp2D"},"outputs":[],"source":["def strain_pressure_chart(df, name, plot_filepath=None):\n","    \"\"\"\n","    Generate a scatter plot of strain and pressure over time.\n","\n","    Parameters:\n","    - df (DataFrame): DataFrame containing strain and pressure data.\n","    - name (str): Name for the plot.\n","\n","    Returns:\n","    None\n","    \"\"\"\n","    fig, ax = plt.subplots(figsize=(6, 6))\n","    ax2 = ax.twinx()\n","\n","    # Scatter plot of pressure over time\n","    ax.scatter(df[\"Time since start (h)\"],\n","               df['Pressure (bar)'],\n","               color=\"aqua\",\n","               marker=\".\",\n","               label=\"_\".join((\"pressure\", df.iloc[0].state_number)))\n","\n","    # Scatter plot of strain over time\n","    # IMORTANT if more than 9 strain gages are in place, edit the following to range(1, 13)\n","    for i in range(1, 10):\n","        ax2.scatter(df['Time since start (h)'],\n","                   df[\"\".join((\"strain\", str(i)))],\n","                   marker=\".\",\n","                   label=(\"_\".join((\"strain\", str(i), df.iloc[0].state_number))))\n","\n","\n","    ax2.legend(bbox_to_anchor=(1.2, 1.0), loc='upper left')\n","    ax.legend(bbox_to_anchor=(1.2, 1.0), loc='lower left')\n","\n","    ax.set_xlabel(\"Time Elapsed (h)\")\n","    ax2.set_ylabel(\"Strain\")\n","    ax.set_ylabel(\"Pressure (bar)\")\n","\n","    # Save the plot if plot_filepath is provided\n","    if plot_filepath:\n","        plt.savefig(plot_filepath, format='png', bbox_inches='tight')\n","        plt.close()  # Close the plot to prevent it from being displayed\n","    else:\n","        plt.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"08OJvYvjsp2D"},"outputs":[],"source":["def generate_subsets(df_full):\n","    \"\"\"\n","    Generate subsets of df_full based on unique state numbers.\n","\n","    Parameters:\n","    - df_full (DataFrame): DataFrame containing the full data.\n","\n","    Returns:\n","    - subsets (dict): Dictionary containing subsets of df_full indexed by state numbers.\n","    \"\"\"\n","    subsets = {}\n","    state_numbers = df_full['state_number'].unique()\n","\n","    for state_number in state_numbers:\n","        df_subset = df_full[df_full['state_number'] == state_number].copy()\n","\n","        df_subset.sort_index(inplace=True)  # Sort by index (Timestamp)\n","        df_subset['Time since start (s)'] = (df_subset.index - df_subset.index[0]).total_seconds()\n","        df_subset['Time since start (h)'] = df_subset['Time since start (s)'] / 3600\n","        # When the filename is changing reset the time since start to zero and add it to the last value of the previous filename\n","\n","        prev_filename = None\n","        time_offset = 0\n","        for idx, row in df_subset.iterrows():\n","            if row['filename'] != prev_filename:\n","                prev_filename = row['filename']\n","                time_offset = row['Time since start (s)']\n","            df_subset.at[idx, 'Time since start (s)'] -= time_offset\n","            df_subset.at[idx, 'Time since start (h)'] = df_subset.at[idx, 'Time since start (s)'] / 3600\n","\n","        # Calculate volume differences and cumulative sum\n","        df_subset['vol_diff'] = df_subset['Volume (L)'].diff()\n","        df_subset['Volume cumulative sum'] = df_subset['vol_diff'].cumsum()\n","\n","        # Adjust volume cumulative sum for continuity between different filenames\n","        filenames_sorted = np.sort(df_subset['filename'].unique())\n","        if len(filenames_sorted) > 1:\n","            for fn_idx in range(1, len(filenames_sorted)):\n","                prev_filename = filenames_sorted[fn_idx - 1]\n","                curr_filename = filenames_sorted[fn_idx]\n","                prev_last_vol = df_subset[df_subset['filename'] == prev_filename]['Volume (L)'].iloc[-1]\n","                curr_first_vol = df_subset[df_subset['filename'] == curr_filename]['Volume (L)'].iloc[0]\n","                df_subset.loc[df_subset['filename'] == curr_filename, 'Volume cumulative sum'] += prev_last_vol\n","                prev_last_time = df_subset[df_subset['filename'] == prev_filename]['Time since start (s)'].iloc[-1]\n","                df_subset.loc[df_subset['filename'] == curr_filename, 'Time since start (s)'] += prev_last_time\n","                df_subset['Time since start (h)'] = df_subset['Time since start (s)'] / 3600\n","\n","        subsets[state_number] = df_subset\n","\n","    return subsets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"20r22bsxsp2D","outputId":"7dac675a-8b80-4367-d33e-b9d7f3daa7fe"},"outputs":[{"name":"stderr","output_type":"stream","text":["No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n","No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n","No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n","No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n","No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n","No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n","No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n","No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"]}],"source":["# Step 1: Generate subsets\n","subsets = generate_subsets(df_full)\n","\n","# Step 2: Iterate over subsets and plot charts\n","for state_number, df_subset in subsets.items():\n","    flow_rate_chart(df_subset, state_number)\n","    volume_chart(df_subset, state_number)\n","    pressure_chart(df_subset, state_number)\n","    # IMPORTANT: if more than 9 strain gages are in place, edit the following to if {'strain1', 'strain2', 'strain3', 'strain4', 'strain5', 'strain6', 'strain7', 'strain8', 'strain9', 'strain10', 'strain11', 'strain12'}\n","    if {'strain1', 'strain2', 'strain3', 'strain4', 'strain5', 'strain6', 'strain7', 'strain8', 'strain9'}.issubset(df_full.columns):\n","        strain_pressure_chart(df_subset, state_number)\n","    # IMPORTANT: if different thermocouples are in place, edit according to the PicoLog file\n","    if 'Rig 2 IN Last (C)' in df_full.columns and 'Rig 2 OUT Last (C)' in df_full.columns:\n","        flow_rate_temp_chart(df_subset, state_number, ['Rig 2 IN Last (C)', 'Rig 2 OUT Last (C)'])"]},{"cell_type":"markdown","metadata":{"id":"ahfFaQr1sp2E"},"source":["# Save"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PpzlyLVnsp2E"},"outputs":[],"source":["def export_subsets_to_csv_and_plots(subsets, folderpath):\n","    \"\"\"\n","    Export each subset DataFrame to a CSV file with the state number in the filename,\n","    and save corresponding plots.\n","\n","    Parameters:\n","    - subsets (dict): Dictionary of DataFrames indexed by state numbers.\n","    - folderpath (str): Path to the folder where CSV files and plots will be saved.\n","    \"\"\"\n","    # Create the folder if it doesn't exist\n","    if not os.path.exists(folderpath):\n","        os.makedirs(folderpath)\n","\n","    # Create the \"processed raw data\" folder if it doesn't exist\n","    processed_raw_data_folder = os.path.join(folderpath, \"processed raw data\")\n","    if not os.path.exists(processed_raw_data_folder):\n","        os.makedirs(processed_raw_data_folder)\n","\n","    # Move the CSV files used during the code execution to the \"processed raw data\" folder\n","    for filename in os.listdir():\n","        if filename.endswith(\"-10s.csv\"):\n","            shutil.move(filename, os.path.join(processed_raw_data_folder, filename))\n","        elif filename.count(\"-\") == 4 and filename.endswith(\".csv\"):\n","            state_number = filename.split(\"-\")[3]\n","            shutil.move(filename, os.path.join(processed_raw_data_folder, filename))\n","        elif filename.count(\"-\") == 1 and filename.endswith(\".csv\"):\n","            state_number = filename.split(\"-\")[1]\n","            shutil.move(filename, os.path.join(processed_raw_data_folder, filename))\n","\n","    # Create the \"collated data\" folder if it doesn't exist\n","    collated_data_folder = os.path.join(folderpath, \"collated data\")\n","    if not os.path.exists(collated_data_folder):\n","        os.makedirs(collated_data_folder)\n","\n","    # Export each subset DataFrame to a CSV file and save plots\n","    for state_number, df_subset in subsets.items():\n","        # Define the filename with the state number for CSV\n","        csv_filename = f\"{state_number}_collated.csv\"\n","        # Construct the full file path for CSV\n","        csv_filepath = os.path.join(collated_data_folder, csv_filename)\n","        # Export the subset DataFrame to CSV\n","        df_subset.to_csv(csv_filepath, index=True)\n","\n","        # Save all the plots\n","        plot_filename = f\"{state_number}_flow_rate_chart.png\"\n","        plot_filepath = os.path.join(collated_data_folder, plot_filename)\n","        flow_rate_chart(df_subset, state_number, plot_filepath)\n","\n","        plot_filename = f\"{state_number}_volume_chart.png\"\n","        plot_filepath = os.path.join(collated_data_folder, plot_filename)\n","        volume_chart(df_subset, state_number, plot_filepath)\n","\n","        plot_filename = f\"{state_number}_pressure_chart.png\"\n","        plot_filepath = os.path.join(collated_data_folder, plot_filename)\n","        pressure_chart(df_subset, state_number, plot_filepath)\n","\n","        if {'strain1', 'strain2', 'strain3', 'strain4', 'strain5', 'strain6', 'strain7', 'strain8', 'strain9'}.issubset(df_subset.columns):\n","            plot_filename = f\"{state_number}_strain_pressure_chart.png\"\n","            plot_filepath = os.path.join(collated_data_folder, plot_filename)\n","            strain_pressure_chart(df_subset, state_number, plot_filepath)\n","\n","        if 'Rig 2 IN Last (C)' in df_subset.columns and 'Rig 2 OUT Last (C)' in df_subset.columns:\n","            plot_filename = f\"{state_number}_flow_rate_temp_chart.png\"\n","            plot_filepath = os.path.join(collated_data_folder, plot_filename)\n","            flow_rate_temp_chart(df_subset, state_number, ['Rig 2 IN Last (C)', 'Rig 2 OUT Last (C)'], plot_filepath)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k43Kzevesp2E","outputId":"fdc3bffe-cde8-418b-ec4b-fb0ffaddec37"},"outputs":[{"name":"stderr","output_type":"stream","text":["No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n","No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n","No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n","No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n","No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n","No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n","No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n","No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"]}],"source":["folderpath = \"C:\\\\Users\\\\Sebastiano Gadolini\\\\Documents\\\\Python Scripts\\\\MogRig_DataAnalysis\\\\\"\n","\n","export_subsets_to_csv_and_plots(subsets, folderpath)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P8ZeRXP4sp2E"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
